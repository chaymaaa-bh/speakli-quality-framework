{
  "report": {
    "global": {
      "nb_samples": 29,
      "cer_mean": 0.119,
      "wer_mean": 0.5036,
      "resident_accuracy": 0.7241
    },
    "by_task": {
      "vitals": {
        "count": 9,
        "cer_mean": 0.1551,
        "wer_mean": 0.5903,
        "vitals_match_mean": 0.5185
      },
      "targeted": {
        "count": 10,
        "cer_mean": 0.101,
        "wer_mean": 0.452,
        "rougeL_mean": 0.6769
      },
      "narrative": {
        "count": 10,
        "cer_mean": 0.1046,
        "wer_mean": 0.4771,
        "section_f1_mean": 0.7491,
        "rougeL_mean": 0.7256
      }
    }
  },
  "details": [
    {
      "id": "v01",
      "task_type": "vitals",
      "cer": 0.06140350877192982,
      "wer": 0.3684210526315789,
      "resident_ok": 1,
      "vitals_match": 1.0
    },
    {
      "id": "t01",
      "task_type": "targeted",
      "cer": 0.03875968992248062,
      "wer": 0.21739130434782608,
      "resident_ok": 1,
      "rougeL_targeted": 0.6093,
      "target_exact": 1.0
    },
    {
      "id": "n01",
      "task_type": "narrative",
      "cer": 0.06666666666666667,
      "wer": 0.2631578947368421,
      "resident_ok": 1,
      "section_f1": 0.75,
      "rougeL_narrative": 0.7885
    },
    {
      "id": "t02",
      "task_type": "targeted",
      "cer": 0.09523809523809523,
      "wer": 0.47619047619047616,
      "resident_ok": 0,
      "rougeL_targeted": 0.6807,
      "target_exact": 1.0
    },
    {
      "id": "n02",
      "task_type": "narrative",
      "cer": 0.045454545454545456,
      "wer": 0.3333333333333333,
      "resident_ok": 1,
      "section_f1": 0.8,
      "rougeL_narrative": 0.8333
    },
    {
      "id": "v02",
      "task_type": "vitals",
      "cer": 0.0784313725490196,
      "wer": 0.3333333333333333,
      "resident_ok": 1,
      "vitals_match": 0.6667
    },
    {
      "id": "t03",
      "task_type": "targeted",
      "cer": 0.20430107526881722,
      "wer": 0.5,
      "resident_ok": 1,
      "rougeL_targeted": 0.8235,
      "target_exact": 1.0
    },
    {
      "id": "n03",
      "task_type": "narrative",
      "cer": 0.07462686567164178,
      "wer": 0.35,
      "resident_ok": 1,
      "section_f1": 0.6667,
      "rougeL_narrative": 1.0
    },
    {
      "id": "v03",
      "task_type": "vitals",
      "cer": 0.09722222222222222,
      "wer": 0.6,
      "resident_ok": 0,
      "vitals_match": 0.5
    },
    {
      "id": "n04",
      "task_type": "narrative",
      "cer": 0.07103825136612021,
      "wer": 0.4230769230769231,
      "resident_ok": 1,
      "section_f1": 0.75,
      "rougeL_narrative": 0.7389
    },
    {
      "id": "v04",
      "task_type": "vitals",
      "cer": 0.29577464788732394,
      "wer": 0.8,
      "resident_ok": 1,
      "vitals_match": 0.0
    },
    {
      "id": "t04",
      "task_type": "targeted",
      "cer": 0.0893854748603352,
      "wer": 0.28125,
      "resident_ok": 1,
      "rougeL_targeted": 0.5619,
      "target_exact": 1.0
    },
    {
      "id": "v05",
      "task_type": "vitals",
      "cer": 0.2698412698412698,
      "wer": 0.9090909090909091,
      "resident_ok": 1,
      "vitals_match": 0.5
    },
    {
      "id": "t05",
      "task_type": "targeted",
      "cer": 0.12138728323699421,
      "wer": 0.5185185185185185,
      "resident_ok": 0,
      "rougeL_targeted": 0.7389,
      "target_exact": 1.0
    },
    {
      "id": "n05",
      "task_type": "narrative",
      "cer": 0.12021857923497267,
      "wer": 0.5925925925925926,
      "resident_ok": 1,
      "section_f1": 1.0,
      "rougeL_narrative": 0.8929
    },
    {
      "id": "t06",
      "task_type": "targeted",
      "cer": 0.09655172413793103,
      "wer": 0.6666666666666666,
      "resident_ok": 1,
      "rougeL_targeted": 0.6333,
      "target_exact": 1.0
    },
    {
      "id": "n06",
      "task_type": "narrative",
      "cer": 0.08379888268156424,
      "wer": 0.3793103448275862,
      "resident_ok": 0,
      "section_f1": 0.0,
      "rougeL_narrative": 0.0
    },
    {
      "id": "v06",
      "task_type": "vitals",
      "cer": 0.1111111111111111,
      "wer": 0.5,
      "resident_ok": 0,
      "vitals_match": 0.0
    },
    {
      "id": "t07",
      "task_type": "targeted",
      "cer": 0.09433962264150944,
      "wer": 0.37037037037037035,
      "resident_ok": 1,
      "rougeL_targeted": 0.6625,
      "target_exact": 1.0
    },
    {
      "id": "n07",
      "task_type": "narrative",
      "cer": 0.11515151515151516,
      "wer": 0.5,
      "resident_ok": 0,
      "section_f1": 0.8571,
      "rougeL_narrative": 0.7083
    },
    {
      "id": "v07",
      "task_type": "vitals",
      "cer": 0.1650485436893204,
      "wer": 0.5263157894736842,
      "resident_ok": 1,
      "vitals_match": 1.0
    },
    {
      "id": "t08",
      "task_type": "targeted",
      "cer": 0.0783132530120482,
      "wer": 0.375,
      "resident_ok": 1,
      "rougeL_targeted": 0.7778,
      "target_exact": 1.0
    },
    {
      "id": "n08",
      "task_type": "narrative",
      "cer": 0.09868421052631579,
      "wer": 0.391304347826087,
      "resident_ok": 0,
      "section_f1": 0.6667,
      "rougeL_narrative": 0.575
    },
    {
      "id": "t09",
      "task_type": "targeted",
      "cer": 0.08641975308641975,
      "wer": 0.4090909090909091,
      "resident_ok": 1,
      "rougeL_targeted": 0.5668,
      "target_exact": 1.0
    },
    {
      "id": "n09",
      "task_type": "narrative",
      "cer": 0.2518518518518518,
      "wer": 0.9130434782608695,
      "resident_ok": 1,
      "section_f1": 1.0,
      "rougeL_narrative": 1.0
    },
    {
      "id": "v08",
      "task_type": "vitals",
      "cer": 0.1885245901639344,
      "wer": 0.6086956521739131,
      "resident_ok": 1,
      "vitals_match": 0.0
    },
    {
      "id": "t10",
      "task_type": "targeted",
      "cer": 0.1048951048951049,
      "wer": 0.7058823529411765,
      "resident_ok": 1,
      "rougeL_targeted": 0.7146,
      "target_exact": 1.0
    },
    {
      "id": "n10",
      "task_type": "narrative",
      "cer": 0.11875,
      "wer": 0.625,
      "resident_ok": 1,
      "section_f1": 1.0,
      "rougeL_narrative": 0.7191
    },
    {
      "id": "v09",
      "task_type": "vitals",
      "cer": 0.12857142857142856,
      "wer": 0.6666666666666666,
      "resident_ok": 0,
      "vitals_match": 1.0
    }
  ]
}